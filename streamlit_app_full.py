#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
PDFè¶‹åŠ¿å¼ºåº¦æå–å·¥å…· - Streamlitç‰ˆæœ¬

åŠŸèƒ½ï¼š
1. ç›´æ¥ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
2. è¯†åˆ«å¹¶æå–ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†çš„å“ç§ä¿¡æ¯
3. è¾“å‡ºæŒ‰å“ç§å’ŒæŒ‰æ—¥æœŸåˆ†ç±»çš„CSVæ–‡ä»¶
4. æ”¯æŒWebç•Œé¢æ–‡ä»¶ä¸Šä¼ 
"""

import os
import re
import csv
import io
from pathlib import Path
from datetime import datetime
from io import BytesIO
import pandas as pd
import streamlit as st

try:
    import fitz  # PyMuPDF
except ImportError:
    st.error("é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ PyMuPDF")
    st.error("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install PyMuPDF")
    st.stop()


def extract_text_from_pdf(pdf_file, max_pages=None):
    """
    ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    
    Args:
        pdf_file: PDFæ–‡ä»¶å¯¹è±¡æˆ–è·¯å¾„
        max_pages: æœ€å¤§æå–é¡µæ•°ï¼ŒNoneè¡¨ç¤ºæå–æ‰€æœ‰é¡µ
        
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹
    """
    try:
        # å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡ï¼Œè¯»å–å­—èŠ‚æ•°æ®
        if hasattr(pdf_file, 'read'):
            pdf_bytes = pdf_file.read()
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        else:
            doc = fitz.open(pdf_file)
            
        total_pages = len(doc)
        pages_to_extract = min(total_pages, max_pages) if max_pages else total_pages
        
        st.info(f"å¼€å§‹æå–PDFæ–‡ä»¶ (å…± {total_pages} é¡µï¼Œå°†æå– {pages_to_extract} é¡µ)")
        
        # æå–æ–‡æœ¬
        text_content = []
        for page_num in range(pages_to_extract):
            page = doc.load_page(page_num)
            text = page.get_text("text")
            text_content.append(text)
            
        doc.close()
        return "\n\n".join(text_content)
    
    except Exception as e:
        st.error(f"æå–PDFæ–‡æœ¬æ—¶å‡ºé”™: {str(e)}")
        return ""


def extract_trend_strength_from_text(text, report_date=None):
    """
    ä»æ–‡æœ¬ä¸­æå–è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯
    
    Args:
        text: æ–‡æœ¬å†…å®¹
        report_date: æŠ¥å‘Šæ—¥æœŸ
        
    Returns:
        æå–çš„è¶‹åŠ¿å¼ºåº¦æ•°æ®åˆ—è¡¨
    """
    trend_data = []
    
    # å°è¯•ä»æ–‡ä»¶åæˆ–å†…å®¹ä¸­æå–æ—¥æœŸ
    if not report_date:
        date_patterns = [
            r'(\d{4})(\d{2})(\d{2})',
            r'(\d{4})-(\d{2})-(\d{2})',
            r'(\d{4})/(\d{2})/(\d{2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                year, month, day = match.groups()
                report_date = f"{year}-{month}-{day}"
                break
    
    if not report_date:
        report_date = datetime.now().strftime("%Y-%m-%d")
    
    st.info("æ­£åœ¨æŸ¥æ‰¾è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯...")
    
    # æŸ¥æ‰¾è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯ - åŒ¹é…"è¶‹åŠ¿å¼ºåº¦ï¼š"å‰é¢çš„å“ç§åï¼ˆæ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€æ‹¬å·ç­‰ï¼Œå…è®¸ç©ºæ ¼ï¼‰
    patterns = [
        r'([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()]+)\s*è¶‹åŠ¿å¼ºåº¦[ï¼š:]\s*([+-]?\d+(?:\.\d+)?)',
    ]
    
    found_data = set()  # ç”¨äºå»é‡
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        st.info(f"ä½¿ç”¨æ¨¡å¼ {pattern} æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…é¡¹")
        
        for match in matches:
            if len(match) == 2:
                variety, strength = match
                variety = variety.strip()
                
                # è¿‡æ»¤æ‰ä¸€äº›æ— æ•ˆçš„å“ç§åå’Œé‡å¤çš„å“ç§
                # ç§»é™¤å“ç§åä¸­çš„"è¶‹åŠ¿å¼ºåº¦"åç¼€ï¼ˆå¦‚"ä¸é”ˆé’¢è¶‹åŠ¿å¼ºåº¦"å˜ä¸º"ä¸é”ˆé’¢"ï¼‰
                if variety.endswith('è¶‹åŠ¿å¼ºåº¦'):
                    variety = variety[:-4]  # ç§»é™¤"è¶‹åŠ¿å¼ºåº¦"4ä¸ªå­—ç¬¦
                
                # è¿‡æ»¤æ¡ä»¶ï¼š
                # 1. å“ç§åé•¿åº¦å¤§äº0
                # 2. ä¸åŒ…å«æ— æ•ˆå…³é”®è¯
                # 3. ä¸æ˜¯çº¯æ•°å­—
                # 4. åŒ…å«ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å­—ç¬¦ã€æ•°å­—ã€æ‹¬å·ç­‰åˆæ³•å­—ç¬¦
                invalid_keywords = ['è¶‹åŠ¿', 'å¼ºåº¦', 'æ³¨é‡Š', 'ä¸œè', 'è¾¾å­š', 'å…¬å¸', 'æœ‰é™', 'é›†å›¢']
                if (len(variety) > 0 and 
                    not any(keyword in variety for keyword in invalid_keywords) and
                    not variety.isdigit() and
                    re.match(r'^[\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()]+$', variety)):
                    try:
                        # å…ˆè½¬æ¢ä¸ºæµ®ç‚¹æ•°è¿›è¡ŒèŒƒå›´éªŒè¯ï¼Œä½†ä¿å­˜åŸå§‹å­—ç¬¦ä¸²
                        strength_float = float(strength)
                        # ç¡®ä¿è¶‹åŠ¿å¼ºåº¦åœ¨åˆç†èŒƒå›´å†…
                        if -10 <= strength_float <= 10:
                            # ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ä½œä¸ºè¶‹åŠ¿å€¼
                            key = (variety, strength)
                            if key not in found_data:
                                found_data.add(key)
                                trend_data.append({
                                    'å“ç§': variety,
                                    'è¶‹åŠ¿å¼ºåº¦': strength,  # ä¿å­˜åŸå§‹å­—ç¬¦ä¸²
                                    'è¶‹åŠ¿å¼ºåº¦_float': strength_float,  # ä¿å­˜æµ®ç‚¹æ•°ç”¨äºè®¡ç®—
                                    'æ—¥æœŸ': report_date
                                })
                                st.success(f"æå–: {variety} = {strength}")
                    except ValueError:
                        st.warning(f"è·³è¿‡æ— æ•ˆæ•°å€¼: {variety} = {strength}")
                        continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œå°è¯•æŸ¥æ‰¾ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†çš„æ ¼å¼
    if not trend_data:
        st.warning("æœªæ‰¾åˆ°æ ‡å‡†æ ¼å¼çš„è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯ï¼Œå°è¯•æŸ¥æ‰¾ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†...")
        
        # æŸ¥æ‰¾ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ† - æ›´å®½æ¾çš„åŒ¹é…
        trend_patterns = [
            r'ã€è¶‹åŠ¿å¼ºåº¦ã€‘([\s\S]*?)(?=ã€|$)',
            r'è¶‹åŠ¿å¼ºåº¦([\s\S]*?)(?=ã€|$)',
            r'\[è¶‹åŠ¿å¼ºåº¦\]([\s\S]*?)(?=\[|$)'
        ]
        
        trend_content = None
        for pattern in trend_patterns:
            trend_match = re.search(pattern, text, re.IGNORECASE)
            if trend_match:
                trend_content = trend_match.group(1)
                st.success(f"æ‰¾åˆ°è¶‹åŠ¿å¼ºåº¦å†…å®¹ï¼Œä½¿ç”¨æ¨¡å¼: {pattern}")
                break
        
        if trend_content:
            st.info(f"è¶‹åŠ¿å¼ºåº¦å†…å®¹é•¿åº¦: {len(trend_content)} å­—ç¬¦")
            
            # æå–åå¼ºã€ä¸­æ€§ã€åå¼±å“ç§
            categories = {
                'åå¼º': 1,
                'ä¸­æ€§': 0, 
                'åå¼±': -1
            }
            
            for category, strength_value in categories.items():
                st.info(f"æ­£åœ¨æŸ¥æ‰¾{category}å“ç§...")
                
                # å¤šç§åŒ¹é…æ¨¡å¼
                patterns = [
                    rf'{category}[ï¼š:](.*?)(?=(?:åå¼º|ä¸­æ€§|åå¼±)[ï¼š:]|$)',
                    rf'{category}\s*[ï¼š:]\s*(.*?)(?=(?:åå¼º|ä¸­æ€§|åå¼±)|$)',
                    rf'{category}\s*[:ï¼š]\s*(.*?)(?=\n\n|\n[^\u4e00-\u9fff]|$)'
                ]
                
                content = None
                for pattern in patterns:
                    match = re.search(pattern, trend_content, re.DOTALL | re.IGNORECASE)
                    if match:
                        content = match.group(1).strip()
                        st.success(f"æ‰¾åˆ°{category}å†…å®¹ï¼Œä½¿ç”¨æ¨¡å¼: {pattern}")
                        break
                
                if content:
                    # æå–å“ç§å’Œæ•°å­— - æ”¯æŒå¤šç§æ ¼å¼
                    variety_patterns = [
                        r'([\u4e00-\u9fff]+)\s*[ï¼ˆ(]([+-]?\d+(?:\.\d+)?)[ï¼‰)]',  # å“ç§å(æ•°å­—)
                        r'([\u4e00-\u9fff]+)\s*[ï¼š:]\s*([+-]?\d+(?:\.\d+)?)',    # å“ç§å: æ•°å­—
                        r'([\u4e00-\u9fff]+)\s+([+-]?\d+(?:\.\d+)?)',          # å“ç§å æ•°å­—
                    ]
                    
                    varieties = []
                    for var_pattern in variety_patterns:
                        found = re.findall(var_pattern, content)
                        if found:
                            varieties.extend(found)
                    
                    # å»é‡
                    seen = set()
                    unique_varieties = []
                    for variety, number in varieties:
                        key = variety.strip()
                        if key not in seen:
                            seen.add(key)
                            unique_varieties.append((variety, number))
                    
                    for i, (variety, number) in enumerate(unique_varieties, 1):
                        try:
                            # å…ˆè½¬æ¢ä¸ºæµ®ç‚¹æ•°è¿›è¡ŒéªŒè¯ï¼Œä½†ä¿å­˜åŸå§‹å­—ç¬¦ä¸²
                            number_float = float(number)
                            # ç¡®ä¿è¶‹åŠ¿å¼ºåº¦åœ¨åˆç†èŒƒå›´å†…
                            if -10 <= number_float <= 10:
                                trend_data.append({
                                    'å“ç§': variety.strip(),
                                    'è¶‹åŠ¿å¼ºåº¦': number,  # ä¿å­˜åŸå§‹å­—ç¬¦ä¸²
                                    'è¶‹åŠ¿å¼ºåº¦_float': number_float,  # ä¿å­˜æµ®ç‚¹æ•°ç”¨äºè®¡ç®—
                                    'åºå·': i,
                                    'ç±»åˆ«': category,
                                    'æ—¥æœŸ': report_date
                                })
                                st.success(f"æå–: {variety.strip()} = {number}")
                        except ValueError:
                            st.warning(f"è·³è¿‡æ— æ•ˆæ•°å€¼: {variety} = {number}")
                            continue
                else:
                    st.warning(f"æœªæ‰¾åˆ°{category}å“ç§å†…å®¹")
    
    if trend_data:
        st.success(f"å…±æå–åˆ° {len(trend_data)} ä¸ªå“ç§çš„è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯")
    else:
        st.error("æœªæ‰¾åˆ°ä»»ä½•è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯")
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        lines_with_trend = [line.strip() for line in text.split('\n') 
                           if 'è¶‹åŠ¿å¼ºåº¦' in line and line.strip()]
        if lines_with_trend:
            st.info("åŒ…å«'è¶‹åŠ¿å¼ºåº¦'çš„æ–‡æœ¬è¡Œ:")
            for line in lines_with_trend[:5]:  # åªæ˜¾ç¤ºå‰5è¡Œ
                st.text(f"  {line}")
        else:
            st.warning("æ–‡æ¡£ä¸­æœªæ‰¾åˆ°åŒ…å«'è¶‹åŠ¿å¼ºåº¦'çš„æ–‡æœ¬è¡Œ")
    
    return trend_data


def save_trend_strength_pivot_csv(all_trend_data, output_dir=None, incremental=True):
    """
    å°†è¶‹åŠ¿å¼ºåº¦æ•°æ®ä¿å­˜ä¸ºé€è§†è¡¨æ ¼å¼çš„CSVæ–‡ä»¶ï¼Œå¹¶æ ‡è®°å‘ç”Ÿå˜åŒ–çš„å“ç§
    æ”¯æŒå¢é‡æ›´æ–°ï¼Œå¯ä»¥å°†æ–°æ•°æ®åˆå¹¶åˆ°å·²æœ‰æ•°æ®ä¸­
    
    Args:
        all_trend_data: æ‰€æœ‰è¶‹åŠ¿å¼ºåº¦æ•°æ®åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•ï¼ˆåœ¨Streamlitä¸­ä¸ä½¿ç”¨ï¼‰
        incremental: æ˜¯å¦å¯ç”¨å¢é‡æ›´æ–°æ¨¡å¼ï¼Œé»˜è®¤ä¸ºTrue
    
    Returns:
        tuple: (pivot_df, change_df) é€è§†è¡¨å’Œå˜åŒ–æ ‡è®°è¡¨
    """
    if not all_trend_data:
        return None, None
    
    # åˆ›å»ºæ–°æ•°æ®çš„DataFrame
    new_df = pd.DataFrame(all_trend_data)
    
    # å¦‚æœå¯ç”¨å¢é‡æ›´æ–°ä¸”å­˜åœ¨å†å²æ•°æ®ï¼Œåˆ™åˆå¹¶
    if incremental and 'historical_data' in st.session_state:
        st.info("æ£€æµ‹åˆ°å†å²æ•°æ®ï¼Œæ­£åœ¨è¿›è¡Œå¢é‡æ›´æ–°...")
        historical_df = pd.DataFrame(st.session_state.historical_data)
        
        # åˆå¹¶å†å²æ•°æ®å’Œæ–°æ•°æ®
        combined_df = pd.concat([historical_df, new_df], ignore_index=True)
        
        # å»é‡ï¼šåŒä¸€æ—¥æœŸåŒä¸€å“ç§åªä¿ç•™æœ€æ–°çš„è®°å½•
        combined_df = combined_df.drop_duplicates(subset=['æ—¥æœŸ', 'å“ç§'], keep='last')
        
        st.info(f"åˆå¹¶åæ•°æ®é‡: {len(combined_df)} æ¡è®°å½•")
    else:
        combined_df = new_df
        st.info(f"ä½¿ç”¨æ–°æ•°æ®: {len(combined_df)} æ¡è®°å½•")
    
    # æ›´æ–°session_stateä¸­çš„å†å²æ•°æ®
    st.session_state.historical_data = combined_df.to_dict('records')
    
    # ä¿å­˜åˆ°CSVæ–‡ä»¶ä»¥å®ç°æŒä¹…åŒ–
    try:
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        csv_file_path = data_dir / "trend_strength_data.csv"
        combined_df.to_csv(csv_file_path, index=False)
        st.success(f"å·²å°† {len(combined_df)} æ¡æ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶")
    except Exception as e:
        st.error(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    # åˆ›å»ºé€è§†è¡¨ - ä½¿ç”¨æµ®ç‚¹æ•°å­—æ®µè¿›è¡Œè®¡ç®—
    if 'è¶‹åŠ¿å¼ºåº¦_float' in combined_df.columns:
        # ä½¿ç”¨æµ®ç‚¹æ•°å­—æ®µåˆ›å»ºè®¡ç®—ç”¨çš„é€è§†è¡¨
        pivot_calc_df = combined_df.pivot_table(
            index='æ—¥æœŸ', 
            columns='å“ç§', 
            values='è¶‹åŠ¿å¼ºåº¦_float', 
            fill_value=0.0
        )
        
        # ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²åˆ›å»ºæ˜¾ç¤ºç”¨çš„é€è§†è¡¨
        pivot_df = combined_df.pivot_table(
            index='æ—¥æœŸ', 
            columns='å“ç§', 
            values='è¶‹åŠ¿å¼ºåº¦', 
            aggfunc='first',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå€¼ï¼Œå› ä¸ºå­—ç¬¦ä¸²ä¸èƒ½æ±‚å¹³å‡
            fill_value='0'
        )
    else:
        # å‘åå…¼å®¹ï¼Œå¦‚æœæ²¡æœ‰æµ®ç‚¹æ•°å­—æ®µï¼Œåˆ™ä½¿ç”¨åŸå§‹å­—æ®µ
        pivot_df = combined_df.pivot_table(
            index='æ—¥æœŸ', 
            columns='å“ç§', 
            values='è¶‹åŠ¿å¼ºåº¦', 
            fill_value='0'
        )
    
    # æŒ‰æ—¥æœŸæ’åº
    pivot_df = pivot_df.sort_index()
    
    # æ£€æµ‹è¶‹åŠ¿å¼ºåº¦å˜åŒ–å¹¶åˆ›å»ºå˜åŒ–æ ‡è®°è¡¨
    change_df = pivot_df.copy()
    
    # ä½¿ç”¨è®¡ç®—ç”¨çš„é€è§†è¡¨è¿›è¡Œæ¯”è¾ƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    compare_df = pivot_calc_df if 'è¶‹åŠ¿å¼ºåº¦_float' in combined_df.columns else pivot_df
    
    for col in pivot_df.columns:
        for i in range(len(pivot_df)):
            current_value = pivot_df.iloc[i][col]  # æ˜¾ç¤ºç”¨çš„åŸå§‹å­—ç¬¦ä¸²å€¼
            
            if i == 0:
                # ç¬¬ä¸€è¡Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰æ•°å€¼
                change_df.iloc[i, change_df.columns.get_loc(col)] = current_value
            else:
                # ä½¿ç”¨è®¡ç®—ç”¨çš„å€¼è¿›è¡Œæ¯”è¾ƒ
                current_compare = compare_df.iloc[i][col]
                previous_compare = compare_df.iloc[i-1][col]
                
                # å¦‚æœè¶‹åŠ¿å¼ºåº¦å‘ç”Ÿå˜åŒ–ï¼Œç”¨â˜…æ ‡è®°
                if current_compare != previous_compare:
                    change_df.iloc[i, change_df.columns.get_loc(col)] = f'â˜…{current_value}'
                else:
                    # æ²¡æœ‰å˜åŒ–ï¼Œæ­£å¸¸æ˜¾ç¤ºæ•°å€¼
                    change_df.iloc[i, change_df.columns.get_loc(col)] = current_value
    
    # ç»Ÿè®¡å˜åŒ–æƒ…å†µ
    total_changes = 0
    # ä½¿ç”¨è®¡ç®—ç”¨çš„é€è§†è¡¨è¿›è¡Œæ¯”è¾ƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    stats_df = pivot_calc_df if 'è¶‹åŠ¿å¼ºåº¦_float' in combined_df.columns else pivot_df
    
    for col in stats_df.columns:
        for i in range(1, len(stats_df)):
            current_value = stats_df.iloc[i][col]
            previous_value = stats_df.iloc[i-1][col]
            # å¯¹äºæµ®ç‚¹æ•°æ¯”è¾ƒï¼Œä½¿ç”¨ä¸ç­‰äºï¼›å¯¹äºå­—ç¬¦ä¸²ï¼Œéœ€è¦å…ˆç¡®ä¿ä¸æ˜¯'0'å†æ¯”è¾ƒ
            if isinstance(current_value, (int, float)):
                if (current_value != previous_value and 
                    current_value != 0 and previous_value != 0):
                    total_changes += 1
            else:  # å­—ç¬¦ä¸²æƒ…å†µ
                if (current_value != previous_value and 
                    current_value != '0' and previous_value != '0'):
                    total_changes += 1
    
    st.info(f"æ•°æ®ç»´åº¦: {pivot_df.shape[0]} ä¸ªæ—¥æœŸ, {pivot_df.shape[1]} ä¸ªå“ç§")
    st.info(f"æ£€æµ‹åˆ° {total_changes} æ¬¡è¶‹åŠ¿å¼ºåº¦å˜åŒ–ï¼ˆç”¨â˜…æ ‡è®°ï¼‰")
    
    return pivot_df, change_df

def create_download_files(trend_data):
    """
    åˆ›å»ºå¯ä¸‹è½½çš„æ–‡ä»¶
    
    Args:
        trend_data: è¶‹åŠ¿å¼ºåº¦æ•°æ®åˆ—è¡¨
        
    Returns:
        åŒ…å«æ–‡ä»¶å†…å®¹çš„å­—å…¸
    """
    if not trend_data:
        return {}
    
    files = {}
    
    # ç¡®å®šå­—æ®µåï¼ˆæ ¹æ®æ•°æ®ä¸­æ˜¯å¦åŒ…å«æ–‡ä»¶åå­—æ®µï¼‰
    sample_item = trend_data[0]
    base_fields = ['å“ç§', 'è¶‹åŠ¿å¼ºåº¦', 'æ—¥æœŸ']
    optional_fields = []
    
    if 'åºå·' in sample_item:
        optional_fields.append('åºå·')
    if 'ç±»åˆ«' in sample_item:
        optional_fields.append('ç±»åˆ«')
    if 'æ–‡ä»¶å' in sample_item:
        optional_fields.append('æ–‡ä»¶å')
    
    # æ’é™¤è¶‹åŠ¿å¼ºåº¦_floatå­—æ®µï¼Œè¿™ä¸ªå­—æ®µåªç”¨äºå†…éƒ¨è®¡ç®—
    all_fields = base_fields + optional_fields
    
    # æŒ‰å“ç§åˆ†ç»„çš„CSV
    by_variety_csv = io.StringIO()
    writer = csv.DictWriter(by_variety_csv, fieldnames=all_fields)
    writer.writeheader()
    sorted_data = sorted(trend_data, key=lambda x: x['å“ç§'])
    
    # è¿‡æ»¤æ‰è¶‹åŠ¿å¼ºåº¦_floatå­—æ®µ
    filtered_data = []
    for item in sorted_data:
        filtered_item = {k: v for k, v in item.items() if k != 'è¶‹åŠ¿å¼ºåº¦_float'}
        filtered_data.append(filtered_item)
    
    writer.writerows(filtered_data)
    files['trend_strength_by_variety.csv'] = by_variety_csv.getvalue()
    
    # æŒ‰æ—¥æœŸæ’åºçš„CSV
    by_date_csv = io.StringIO()
    date_fields = ['æ—¥æœŸ'] + [f for f in all_fields if f != 'æ—¥æœŸ']
    writer = csv.DictWriter(by_date_csv, fieldnames=date_fields)
    writer.writeheader()
    sorted_data = sorted(trend_data, key=lambda x: x['æ—¥æœŸ'])
    
    # è¿‡æ»¤æ‰è¶‹åŠ¿å¼ºåº¦_floatå­—æ®µ
    filtered_data = []
    for item in sorted_data:
        filtered_item = {k: v for k, v in item.items() if k != 'è¶‹åŠ¿å¼ºåº¦_float'}
        filtered_data.append(filtered_item)
    
    writer.writerows(filtered_data)
    files['trend_strength_by_date.csv'] = by_date_csv.getvalue()
    
    # æŒ‰æ–‡ä»¶ååˆ†ç»„çš„CSVï¼ˆå¦‚æœæœ‰æ–‡ä»¶åä¿¡æ¯ï¼‰
    if 'æ–‡ä»¶å' in sample_item:
        by_file_csv = io.StringIO()
        file_fields = ['æ–‡ä»¶å'] + [f for f in all_fields if f != 'æ–‡ä»¶å']
        writer = csv.DictWriter(by_file_csv, fieldnames=file_fields)
        writer.writeheader()
        sorted_data = sorted(trend_data, key=lambda x: (x.get('æ–‡ä»¶å', ''), x['å“ç§']))
        
        # è¿‡æ»¤æ‰è¶‹åŠ¿å¼ºåº¦_floatå­—æ®µ
        filtered_data = []
        for item in sorted_data:
            filtered_item = {k: v for k, v in item.items() if k != 'è¶‹åŠ¿å¼ºåº¦_float'}
            filtered_data.append(filtered_item)
        
        writer.writerows(filtered_data)
        files['trend_strength_by_file.csv'] = by_file_csv.getvalue()
    
    # Excelæ ¼å¼
    # è¿‡æ»¤æ‰è¶‹åŠ¿å¼ºåº¦_floatå­—æ®µ
    filtered_data = []
    for item in trend_data:
        filtered_item = {k: v for k, v in item.items() if k != 'è¶‹åŠ¿å¼ºåº¦_float'}
        filtered_data.append(filtered_item)
    
    df = pd.DataFrame(filtered_data)
    excel_buffer = io.BytesIO()
    df.to_excel(excel_buffer, index=False)
    files['trend_strength_summary.xlsx'] = excel_buffer.getvalue()
    
    return files


def analyze_pdf_trend_strength(pdf_file, filename=None):
    """
    åˆ†æPDFæ–‡ä»¶ä¸­çš„è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯
    
    Args:
        pdf_file: PDFæ–‡ä»¶å¯¹è±¡
        filename: æ–‡ä»¶å
        
    Returns:
        æå–çš„è¶‹åŠ¿å¼ºåº¦æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
    """
    st.info(f"å¼€å§‹åˆ†æPDFæ–‡ä»¶: {filename or 'uploaded file'}")
    
    # ä»PDFæå–æ–‡æœ¬
    text_content = extract_text_from_pdf(pdf_file)
    if not text_content:
        st.error("æ— æ³•ä»PDFæå–æ–‡æœ¬å†…å®¹")
        return [], {}
    
    st.info(f"æå–çš„æ–‡æœ¬é•¿åº¦: {len(text_content)} å­—ç¬¦")
    
    # å°è¯•ä»æ–‡ä»¶åæå–æ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨8ä½æ•°å­—æ ¼å¼ï¼‰
    report_date = None
    if filename:
        st.info(f"æ­£åœ¨ä»æ–‡ä»¶åæå–æ—¥æœŸ: {filename}")
        # ä¼˜å…ˆåŒ¹é…8ä½è¿ç»­æ•°å­—ï¼ˆYYYYMMDDæ ¼å¼ï¼‰
        date_match = re.search(r'(\d{8})', filename)
        if date_match:
            date_str = date_match.group(1)
            try:
                # éªŒè¯æ—¥æœŸæ ¼å¼å¹¶è½¬æ¢
                year, month, day = date_str[:4], date_str[4:6], date_str[6:8]
                report_date = f"{year}-{month}-{day}"
                # éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§
                datetime.strptime(report_date, '%Y-%m-%d')
                st.success(f"ä»æ–‡ä»¶åæå–åˆ°æ—¥æœŸ: {report_date}")
            except ValueError:
                st.warning(f"æ–‡ä»¶åä¸­çš„æ—¥æœŸæ ¼å¼æ— æ•ˆ: {date_str}")
                report_date = None
        else:
            st.warning("æ–‡ä»¶åä¸­æœªæ‰¾åˆ°8ä½æ•°å­—æ—¥æœŸæ ¼å¼ï¼ˆYYYYMMDDï¼‰")
    
    # å¦‚æœæ–‡ä»¶åä¸­æ²¡æœ‰æ‰¾åˆ°æ—¥æœŸï¼Œå°è¯•ä»å†…å®¹ä¸­æå–
    if not report_date:
        st.info("å°è¯•ä»PDFå†…å®¹ä¸­æå–æ—¥æœŸ...")
        date_patterns = [
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
            r'(\d{4})-(\d{2})-(\d{2})',
            r'(\d{4})/(\d{2})/(\d{2})',
            r'(\d{4})(\d{2})(\d{2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text_content)
            if match:
                groups = match.groups()
                if len(groups) == 3:
                    year, month, day = groups
                    report_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                    try:
                        datetime.strptime(report_date, '%Y-%m-%d')
                        st.success(f"ä»å†…å®¹ä¸­æå–åˆ°æ—¥æœŸ: {report_date}")
                        break
                    except ValueError:
                        continue
    
    # å¦‚æœä»ç„¶æ²¡æœ‰æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
    if not report_date:
        report_date = datetime.now().strftime("%Y-%m-%d")
        st.warning(f"æœªæ‰¾åˆ°æœ‰æ•ˆæ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ: {report_date}")
    
    # æå–è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯
    trend_data = extract_trend_strength_from_text(text_content, report_date)
    
    # ä¸ºæ¯æ¡æ•°æ®æ·»åŠ æ–‡ä»¶åä¿¡æ¯
    if trend_data and filename:
        for item in trend_data:
            item['æ–‡ä»¶å'] = filename
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {}
    if trend_data:
        for item in trend_data:
            category = item.get('ç±»åˆ«', 'æœªåˆ†ç±»')
            stats[category] = stats.get(category, 0) + 1
    
    return trend_data, stats


def main():
    """
    Streamlitä¸»åº”ç”¨
    """
    st.set_page_config(
        page_title="PDFè¶‹åŠ¿å¼ºåº¦æå–å·¥å…·",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    st.title("ğŸ“Š PDFè¶‹åŠ¿å¼ºåº¦æå–å·¥å…·")
    st.markdown("---")
    
    # åˆ›å»ºæ•°æ®ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    data_dir = Path("./data")
    data_dir.mkdir(exist_ok=True)
    
    # CSVæ–‡ä»¶è·¯å¾„
    csv_file_path = data_dir / "trend_strength_data.csv"
    
    # åˆå§‹åŒ–session state
    if 'historical_data' not in st.session_state:
        # å°è¯•ä»CSVæ–‡ä»¶åŠ è½½å†å²æ•°æ®
        if csv_file_path.exists():
            try:
                df = pd.read_csv(csv_file_path)
                st.session_state.historical_data = df.to_dict('records')
                st.success(f"å·²ä»CSVæ–‡ä»¶åŠ è½½ {len(df)} æ¡å†å²æ•°æ®")
            except Exception as e:
                st.error(f"åŠ è½½CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                st.session_state.historical_data = []
        else:
            st.session_state.historical_data = []
    
    # æ˜¾ç¤ºå†å²æ•°æ®ç»Ÿè®¡
    if st.session_state.historical_data:
        historical_df = pd.DataFrame(st.session_state.historical_data)
        unique_dates = historical_df['æ—¥æœŸ'].nunique()
        unique_varieties = historical_df['å“ç§'].nunique()
        st.info(f"ğŸ“ˆ å†å²æ•°æ®: {len(st.session_state.historical_data)} æ¡è®°å½•ï¼Œ{unique_dates} ä¸ªæ—¥æœŸï¼Œ{unique_varieties} ä¸ªå“ç§")
        
        # ç”Ÿæˆé€è§†è¡¨ï¼ˆä½¿ç”¨å†å²æ•°æ®ï¼‰
        st.subheader("ğŸ“Š å†å²æ•°æ®å˜åŒ–åˆ†æ")
        pivot_df, change_df = save_trend_strength_pivot_csv(st.session_state.historical_data, incremental=False)
        
        if pivot_df is not None:
            # åªæ˜¾ç¤ºå˜åŒ–æ ‡è®°è¡¨
            st.write("**å˜åŒ–æ ‡è®°è¡¨ï¼ˆâ˜…è¡¨ç¤ºå˜åŒ–ï¼‰:**")
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…Arrowè½¬æ¢é”™è¯¯
            change_df_str = change_df.astype(str)
            st.dataframe(change_df_str, use_container_width=True)
        
        # æ¸…é™¤å†å²æ•°æ®æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²æ•°æ®", help="æ¸…é™¤æ‰€æœ‰å·²ä¿å­˜çš„å†å²æ•°æ®"):
            st.session_state.historical_data = []
            
            # åŒæ—¶åˆ é™¤CSVæ–‡ä»¶
            try:
                data_dir = Path("./data")
                csv_file_path = data_dir / "trend_strength_data.csv"
                if csv_file_path.exists():
                    csv_file_path.unlink()  # åˆ é™¤æ–‡ä»¶
                    st.success("å†å²æ•°æ®å·²æ¸…é™¤ï¼ŒCSVæ–‡ä»¶å·²åˆ é™¤")
                else:
                    st.success("å†å²æ•°æ®å·²æ¸…é™¤")
            except Exception as e:
                st.error(f"åˆ é™¤CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                st.success("å†å²æ•°æ®å·²æ¸…é™¤ï¼Œä½†CSVæ–‡ä»¶åˆ é™¤å¤±è´¥")
            
            st.experimental_rerun()
    
    st.markdown("""
    ### åŠŸèƒ½è¯´æ˜
    - ğŸ“„ **æ‰¹é‡ä¸Šä¼ **: æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶è¿›è¡Œæ‰¹é‡åˆ†æ
    - ğŸ” **æ™ºèƒ½æå–**: ä»PDFæ–‡ä»¶ä¸­æå–è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯
    - ğŸ“Š **åˆ†ç±»è¯†åˆ«**: è¯†åˆ«å¹¶æå–ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†çš„å“ç§ä¿¡æ¯
    - ğŸ·ï¸ **ç±»åˆ«æ”¯æŒ**: æ”¯æŒåå¼ºã€ä¸­æ€§ã€åå¼±ä¸‰ç§ç±»åˆ«
    - ğŸ“ˆ **å¢é‡æ›´æ–°**: è‡ªåŠ¨åˆå¹¶å†å²æ•°æ®ï¼Œæ”¯æŒæ•°æ®ç´¯ç§¯
    - ğŸ’¾ **å¤šæ ¼å¼å¯¼å‡º**: ç”ŸæˆCSVå’ŒExcelæ ¼å¼çš„åˆ†æç»“æœ
    - ğŸ“ **æ–‡ä»¶è¿½è¸ª**: è®°å½•æ¯æ¡æ•°æ®çš„æ¥æºæ–‡ä»¶
    """)
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=['pdf'],
        accept_multiple_files=True,
        help="è¯·ä¸Šä¼ åŒ…å«è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯çš„PDFæ–‡ä»¶ï¼Œæ”¯æŒæ‰¹é‡ä¸Šä¼ "
    )
    
    if uploaded_files:
        if len(uploaded_files) == 1:
            st.success(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_files[0].name}")
        else:
            st.success(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            with st.expander("æŸ¥çœ‹ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨", expanded=False):
                for i, file in enumerate(uploaded_files, 1):
                    st.write(f"{i}. {file.name}")
        
        # åˆ†ææŒ‰é’®
        if st.button("å¼€å§‹åˆ†æ", type="primary"):
            with st.spinner(f"æ­£åœ¨åˆ†æ {len(uploaded_files)} ä¸ªPDFæ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
                all_trend_data = []
                all_stats = {}
                
                # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
                for i, uploaded_file in enumerate(uploaded_files, 1):
                    # åˆ†æPDF
                    trend_data, stats = analyze_pdf_trend_strength(uploaded_file, uploaded_file.name)
                    
                    if trend_data:
                        all_trend_data.extend(trend_data)
                        
                        # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
                        for category, count in stats.items():
                            all_stats[category] = all_stats.get(category, 0) + count
                    else:
                        st.warning(f"âš ï¸ {uploaded_file.name}: æœªèƒ½æå–åˆ°æ•°æ®")
                
                # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
                if all_trend_data:
                    st.success(f"âœ… åˆ†æå®Œæˆï¼š{len(all_trend_data)} æ¡è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯")
                    
                    # ä½¿ç”¨åˆå¹¶åçš„æ•°æ®è¿›è¡Œåç»­å¤„ç†
                    trend_data = all_trend_data
                    stats = all_stats
                else:
                    st.error("æœªèƒ½æå–åˆ°è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯")
                    st.stop()
                
                if trend_data:
                    # æ˜¾ç¤ºç®€åŒ–çš„ç»Ÿè®¡ä¿¡æ¯
                    successful_files = sum(1 for file in uploaded_files if any(item.get('æ–‡ä»¶å', '').startswith(file.name.split('.')[0]) for item in trend_data))
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("åå¼ºå“ç§", stats.get('åå¼º', 0))
                    with col2:
                        st.metric("ä¸­æ€§å“ç§", stats.get('ä¸­æ€§', 0))
                    with col3:
                        st.metric("åå¼±å“ç§", stats.get('åå¼±', 0))
                    
                    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                    st.subheader("ğŸ“‹ æå–ç»“æœ")
                    df = pd.DataFrame(trend_data)
                    st.dataframe(df, use_container_width=True)
                    
                    # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤ºï¼ˆå¦‚æœæœ‰ç±»åˆ«ä¿¡æ¯ï¼‰
                    if trend_data and 'ç±»åˆ«' in trend_data[0]:
                        st.subheader("ğŸ“ˆ æŒ‰ç±»åˆ«åˆ†ç»„")
                        for category in ['åå¼º', 'ä¸­æ€§', 'åå¼±']:
                            category_data = [item for item in trend_data if item.get('ç±»åˆ«') == category]
                            if category_data:
                                with st.expander(f"{category} ({len(category_data)} ä¸ªå“ç§)"):
                                    category_df = pd.DataFrame(category_data)
                                    st.dataframe(category_df, use_container_width=True)
                    
                    # ç”Ÿæˆé€è§†è¡¨ï¼ˆå¯ç”¨å¢é‡æ›´æ–°ï¼‰
                    st.subheader("ğŸ“Š é€è§†è¡¨åˆ†æ")
                    pivot_df, change_df = save_trend_strength_pivot_csv(trend_data, incremental=True)
                    
                    if pivot_df is not None:
                        # æ˜¾ç¤ºé€è§†è¡¨
                        st.write("**åŸå§‹é€è§†è¡¨:**")
                        st.dataframe(pivot_df, use_container_width=True)
                        
                        # æ˜¾ç¤ºå˜åŒ–æ ‡è®°è¡¨
                        st.write("**å˜åŒ–æ ‡è®°è¡¨ï¼ˆâ˜…è¡¨ç¤ºå˜åŒ–ï¼‰:**")
                        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…Arrowè½¬æ¢é”™è¯¯
                        change_df_str = change_df.astype(str)
                        st.dataframe(change_df_str, use_container_width=True)
                    
                    # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
                    files = create_download_files(trend_data)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")
                    
                    # æ ¹æ®æ˜¯å¦æœ‰æ–‡ä»¶åä¿¡æ¯è°ƒæ•´åˆ—æ•°
                    if 'trend_strength_by_file.csv' in files:
                        col1, col2, col3, col4 = st.columns(4)
                    else:
                        col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.download_button(
                            label="ğŸ“„ æŒ‰å“ç§æ’åºCSV",
                            data=files['trend_strength_by_variety.csv'],
                            file_name='trend_strength_by_variety.csv',
                            mime='text/csv'
                        )
                    
                    with col2:
                        st.download_button(
                            label="ğŸ“… æŒ‰æ—¥æœŸæ’åºCSV",
                            data=files['trend_strength_by_date.csv'],
                            file_name='trend_strength_by_date.csv',
                            mime='text/csv'
                        )
                    
                    with col3:
                        if 'trend_strength_by_file.csv' in files:
                            st.download_button(
                                label="ğŸ“ æŒ‰æ–‡ä»¶åˆ†ç»„CSV",
                                data=files['trend_strength_by_file.csv'],
                                file_name='trend_strength_by_file.csv',
                                mime='text/csv'
                            )
                        else:
                            # é€è§†è¡¨CSVä¸‹è½½
                            if pivot_df is not None:
                                pivot_csv = pivot_df.to_csv(encoding='utf-8-sig')
                                st.download_button(
                                label="ğŸ“Š ä¸‹è½½é€è§†è¡¨CSV",
                                data=pivot_csv,
                                file_name=f"trend_strength_pivot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime='text/csv'
                            )
                    
                    with col4:
                        if 'trend_strength_by_file.csv' in files:
                            # å®Œæ•´Excelä¸‹è½½ï¼ˆåŒ…å«é€è§†è¡¨ï¼‰
                            excel_buffer = io.BytesIO()
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                # åŸå§‹æ•°æ®
                                df = pd.DataFrame(trend_data)
                                df.to_excel(writer, sheet_name='åŸå§‹æ•°æ®', index=False)
                                
                                # é€è§†è¡¨
                                if pivot_df is not None:
                                    pivot_df.to_excel(writer, sheet_name='é€è§†è¡¨')
                                    change_df.to_excel(writer, sheet_name='å˜åŒ–æ ‡è®°è¡¨')
                            
                            st.download_button(
                                label="ğŸ“Š ä¸‹è½½å®Œæ•´Excel",
                                data=excel_buffer.getvalue(),
                                file_name=f"trend_strength_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                            )
                        else:
                            # å•ä¸ªExcelä¸‹è½½
                            st.download_button(
                                label="ğŸ“Š ä¸‹è½½Excel",
                                data=files['trend_strength_summary.xlsx'],
                                file_name='trend_strength_summary.xlsx',
                                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                            )
                    
                else:
                    st.warning("æœªæ‰¾åˆ°è¶‹åŠ¿å¼ºåº¦ä¿¡æ¯")
                    st.info("è¯·ç¡®ä¿PDFæ–‡ä»¶åŒ…å«ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†çš„å†…å®¹")
    
    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.header("ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        ### ğŸ“‹ æ“ä½œæ­¥éª¤
        1. **æ‰¹é‡ä¸Šä¼ **: é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªPDFæ–‡ä»¶
        2. **å¼€å§‹åˆ†æ**: ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
        3. **æŸ¥çœ‹ç»“æœ**: æµè§ˆæå–çš„æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
        4. **ä¸‹è½½æ–‡ä»¶**: é€‰æ‹©éœ€è¦çš„æ ¼å¼ä¸‹è½½ç»“æœ
        
        ### ğŸ“„ æ”¯æŒçš„æ ¼å¼
        - ã€è¶‹åŠ¿å¼ºåº¦ã€‘éƒ¨åˆ†å†…å®¹
        - åå¼ºã€ä¸­æ€§ã€åå¼±åˆ†ç±»
        - å“ç§å(æ•°å­—)æ ¼å¼
        - å“ç§å: æ•°å­—æ ¼å¼
        - æ–‡ä»¶åæ—¥æœŸæ ¼å¼: YYYYMMDD
        
        ### ğŸ’¡ æ‰¹é‡å¤„ç†ä¼˜åŠ¿
        - ä¸€æ¬¡æ€§å¤„ç†å¤šä¸ªæ–‡ä»¶
        - è‡ªåŠ¨åˆå¹¶æ‰€æœ‰æ•°æ®
        - æŒ‰æ–‡ä»¶ååˆ†ç»„å¯¼å‡º
        - å†å²æ•°æ®ç´¯ç§¯åŠŸèƒ½
        """)
        
        st.header("æŠ€æœ¯ä¿¡æ¯")
        st.markdown("""
        - åŸºäºPyMuPDFæå–PDFæ–‡æœ¬
        - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æè¶‹åŠ¿å¼ºåº¦
        - æ”¯æŒå¤šç§æ•°æ®æ ¼å¼è¾“å‡º
        """)


if __name__ == "__main__":
    main()